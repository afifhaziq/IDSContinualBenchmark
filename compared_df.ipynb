{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b43a297-2f70-4005-8bbe-f942aca5ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_1 = pd.read_csv(\"UNSWNB15Full.csv\")\n",
    "df_2 = pd.read_csv(\"CICIDS_full/CICIDS2017_standardised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a445f67a-ef3b-4b74-8d8b-3035d24fa4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labels encoded. Found 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "x = df_2.iloc[:, :-1]\n",
    "y = df_2.iloc[:, -1]\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "class_names = label_encoder.classes_\n",
    "print(f\"✅ Labels encoded. Found {len(class_names)} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c187424-1f38-402f-aa0a-c98957ee8b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         28\n",
       "1         10\n",
       "2         11\n",
       "3          7\n",
       "4          7\n",
       "          ..\n",
       "447910     3\n",
       "447911     0\n",
       "447912     3\n",
       "447913     3\n",
       "447914     3\n",
       "Name: ACK Flag Count, Length: 447915, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['ACK Flag Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db616f50-bce6-4539-8b2f-c2d034bc3653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>38308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>479</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>326</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>15.636364</td>\n",
       "      <td>31.449238</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1095</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3150</td>\n",
       "      <td>3150</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>632.561635</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389</td>\n",
       "      <td>15206</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>3452</td>\n",
       "      <td>6660</td>\n",
       "      <td>1313</td>\n",
       "      <td>0</td>\n",
       "      <td>203.058823</td>\n",
       "      <td>425.778474</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>1092</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3150</td>\n",
       "      <td>3152</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>694.509719</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0                 80           38308                   1   \n",
       "1                389             479                  11   \n",
       "2                 88            1095                  10   \n",
       "3                389           15206                  17   \n",
       "4                 88            1092                   9   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        1                            6   \n",
       "1                        5                          172   \n",
       "2                        6                         3150   \n",
       "3                       12                         3452   \n",
       "4                        6                         3150   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                             6                       6   \n",
       "1                           326                      79   \n",
       "2                          3150                    1575   \n",
       "3                          6660                    1313   \n",
       "4                          3152                    1575   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                       6                 6.000000                0.000000   \n",
       "1                       0                15.636364               31.449238   \n",
       "2                       0               315.000000              632.561635   \n",
       "3                       0               203.058823              425.778474   \n",
       "4                       0               350.000000              694.509719   \n",
       "\n",
       "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0  ...                     20          0.0          0.0            0   \n",
       "1  ...                     32          0.0          0.0            0   \n",
       "2  ...                     32          0.0          0.0            0   \n",
       "3  ...                     32          0.0          0.0            0   \n",
       "4  ...                     32          0.0          0.0            0   \n",
       "\n",
       "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  Label  \n",
       "0            0        0.0        0.0          0          0      0  \n",
       "1            0        0.0        0.0          0          0      0  \n",
       "2            0        0.0        0.0          0          0      0  \n",
       "3            0        0.0        0.0          0          0      0  \n",
       "4            0        0.0        0.0          0          0      0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.concat([x, df_y], axis=1)\n",
    "\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6248b0cc-fbba-4c8a-89be-a41a8dd38d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Helper function to normalize a column name for robust comparison.\n",
    "    Handles capitalization, whitespace, underscores, common abbreviations,\n",
    "    and numerical suffixes.\n",
    "    \"\"\"\n",
    "    # Define a dictionary of replacements for common abbreviations and typos\n",
    "    replacements = {\n",
    "        'forward': 'fwd',\n",
    "        'backward': 'bwd',\n",
    "        'packets': 'pkt',\n",
    "        'packet': 'pkt',\n",
    "        'pkts': 'pkt',\n",
    "        'average': 'avg',\n",
    "        'min': 'min',\n",
    "        'max': 'max',\n",
    "        'std': 'std',\n",
    "        'win': 'win',\n",
    "        'cwr': 'cwe'\n",
    "    }\n",
    "\n",
    "    # Convert to lowercase and handle underscores and spaces\n",
    "    normalized_name = name.lower().strip().replace('_', ' ')\n",
    "    \n",
    "    # Replace full words with abbreviations\n",
    "    for old, new in replacements.items():\n",
    "        normalized_name = normalized_name.replace(old, new)\n",
    "        \n",
    "    # Remove trailing numerical suffixes like '.1' or '.2'\n",
    "    normalized_name = re.sub(r'\\.\\d+$', '', normalized_name)\n",
    "    \n",
    "    # Split into words, sort, and join\n",
    "    words = normalized_name.split()\n",
    "    return ''.join(sorted(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38fa4e78-8c63-4b4f-8d0f-200198a7b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def compare_df_columns(df1: pd.DataFrame, df2: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Compares the column names of two pandas DataFrames and provides detailed\n",
    "    information about any mismatches. This function normalizes names by\n",
    "    ignoring leading/trailing whitespace, capitalization, and specific\n",
    "    abbreviations ('forward'/'fwd', 'backward'/'bwd', 'packets'/'pkt', etc.)\n",
    "    and trailing numerical suffixes (e.g., '.1').\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): The first DataFrame.\n",
    "        df2 (pd.DataFrame): The second DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the following keys:\n",
    "              - 'are_identical': True if columns are identical (name and order), False otherwise.\n",
    "              - 'in_df1_only': A list of original column names present only in df1.\n",
    "              - 'in_df2_only': A list of original column names present only in df2.\n",
    "              - 'order_mismatch': True if normalized column names are the same but the order differs.\n",
    "    \"\"\"\n",
    "    def normalize_name(name):\n",
    "        \"\"\"\n",
    "        Helper function to normalize a column name for robust comparison.\n",
    "        Handles capitalization, whitespace, underscores, common abbreviations,\n",
    "        and numerical suffixes.\n",
    "        \"\"\"\n",
    "        # Define a dictionary of replacements for common abbreviations and typos\n",
    "        replacements = {\n",
    "            'forward': 'fwd',\n",
    "            'backward': 'bwd',\n",
    "            'packets': 'pkt',\n",
    "            'packet': 'pkt',\n",
    "            'pkts': 'pkt',\n",
    "            'average': 'avg',\n",
    "            'min': 'min',\n",
    "            'max': 'max',\n",
    "            'std': 'std',\n",
    "            'win': 'win',\n",
    "            'cwr': 'cwe'\n",
    "        }\n",
    "\n",
    "        # Convert to lowercase and handle underscores and spaces\n",
    "        normalized_name = name.lower().strip().replace('_', ' ')\n",
    "        \n",
    "        # Replace full words with abbreviations\n",
    "        for old, new in replacements.items():\n",
    "            normalized_name = normalized_name.replace(old, new)\n",
    "            \n",
    "        # Remove trailing numerical suffixes like '.1' or '.2'\n",
    "        normalized_name = re.sub(r'\\.\\d+$', '', normalized_name)\n",
    "        \n",
    "        # Split into words, sort, and join\n",
    "        words = normalized_name.split()\n",
    "        return ''.join(sorted(words))\n",
    "\n",
    "    # Normalize the column names for a more flexible comparison\n",
    "    df1_normalized = [normalize_name(col) for col in df1.columns.tolist()]\n",
    "    df2_normalized = [normalize_name(col) for col in df2.columns.tolist()]\n",
    "    \n",
    "    # Get original column names for the output\n",
    "    df1_cols = df1.columns.tolist()\n",
    "    df2_cols = df2.columns.tolist()\n",
    "\n",
    "    # Check for perfect match (name and order)\n",
    "    are_identical = (df1_cols == df2_cols)\n",
    "\n",
    "    # Check for names only (ignoring order and normalization)\n",
    "    df1_map = {normalize_name(col): col for col in df1_cols}\n",
    "    df2_map = {normalize_name(col): col for col in df2_cols}\n",
    "\n",
    "    df1_set = set(df1_normalized)\n",
    "    df2_set = set(df2_normalized)\n",
    "\n",
    "    in_df1_only_normalized = df1_set - df2_set\n",
    "    in_df2_only_normalized = df2_set - df1_set\n",
    "\n",
    "    # Map back to original column names for the result\n",
    "    in_df1_only = sorted([df1_map[name] for name in in_df1_only_normalized])\n",
    "    in_df2_only = sorted([df2_map[name] for name in in_df2_only_normalized])\n",
    "\n",
    "    # Check for order mismatch if normalized names are the same\n",
    "    order_mismatch = (in_df1_only == [] and in_df2_only == []) and not are_identical\n",
    "\n",
    "    return {\n",
    "        'are_identical': are_identical,\n",
    "        'in_df1_only': in_df1_only,\n",
    "        'in_df2_only': in_df2_only,\n",
    "        'order_mismatch': order_mismatch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40db25f8-6ce0-4582-a38a-481954b5883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparing df_1 and df_2 ---\n",
      "Comparison Result: {'are_identical': False, 'in_df1_only': [], 'in_df2_only': [' Destination Port'], 'order_mismatch': False}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Comparing df_1 and df_2 ---\")\n",
    "result = compare_df_columns(df_1, df_2)\n",
    "print(f\"Comparison Result: {result}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5612b347-41b6-4a0e-a94c-b02a68219baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is df_1 columns name:\n",
      "Index(['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
      "       'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
      "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
      "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
      "       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n",
      "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
      "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
      "       'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n",
      "       'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg',\n",
      "       'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg',\n",
      "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
      "       'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n",
      "       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
      "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
      "       'Idle Min', 'Label'],\n",
      "      dtype='object')\n",
      "This is df_2 columns name:\n",
      "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
      "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
      "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
      "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
      "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
      "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
      "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
      "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
      "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
      "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
      "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
      "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
      "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
      "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
      "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
      "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
      "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
      "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
      "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
      "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
      "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
      "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
      "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n",
      "       'Label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"This is df_1 columns name:\")\n",
    "print(df_1.columns)\n",
    "\n",
    "print(\"This is df_2 columns name:\")\n",
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4747b4a-e950-4bcd-971e-bb7b3745ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is df_1 columns name:\n",
      "Index(['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
      "       'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
      "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
      "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
      "       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n",
      "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
      "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
      "       'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n",
      "       'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg',\n",
      "       'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg',\n",
      "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
      "       'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n",
      "       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
      "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
      "       'Idle Min', 'Label'],\n",
      "      dtype='object')\n",
      "This is df_2 columns name:\n",
      "Index([' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
      "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
      "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
      "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
      "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
      "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
      "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
      "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
      "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
      "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
      "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
      "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
      "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
      "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
      "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
      "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
      "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
      "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
      "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
      "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
      "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
      "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
      "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
      "       ' Idle Max', ' Idle Min', 'Label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"This is df_1 columns name:\")\n",
    "print(df_1.columns)\n",
    "\n",
    "print(\"This is df_2 columns name:\")\n",
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0fddd69-1eda-41cb-8a20-f87a11b71f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _coalesce_duplicate_normalized_columns(df: pd.DataFrame, norm_func) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If multiple columns normalize to the same key, coalesce them into one:\n",
    "    keep the left-most column and fill its nulls from the next duplicates.\n",
    "    \"\"\"\n",
    "    if df.empty or df.shape[1] == 0:\n",
    "        return df\n",
    "\n",
    "    # map original col -> normalized key\n",
    "    norm_keys = {col: norm_func(col) for col in df.columns}\n",
    "\n",
    "    # group columns by normalized key\n",
    "    from collections import defaultdict\n",
    "    groups = defaultdict(list)\n",
    "    for col, key in norm_keys.items():\n",
    "        groups[key].append(col)\n",
    "\n",
    "    out = df.copy()\n",
    "    cols_to_drop = []\n",
    "    # for each group with >1 column, coalesce into the left-most\n",
    "    for key, cols in groups.items():\n",
    "        if len(cols) <= 1:\n",
    "            continue\n",
    "        base = cols[0]\n",
    "        for c in cols[1:]:\n",
    "            # fillna from the right-hand duplicate\n",
    "            out[base] = out[base].where(out[base].notna(), out[c])\n",
    "            cols_to_drop.append(c)\n",
    "    if cols_to_drop:\n",
    "        out = out.drop(columns=cols_to_drop)\n",
    "    return out\n",
    "\n",
    "def align_and_sort_dataframes(df1: pd.DataFrame, df2: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Align and sort columns of two DataFrames:\n",
    "      - normalize names\n",
    "      - coalesce duplicate-normalized columns within each DF\n",
    "      - choose a canonical label per normalized key (prefer df1's original name)\n",
    "      - rename, then reindex to the same sorted union of canonical columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Optional one-off removal you had\n",
    "    if ' Destination Port' in df2.columns:\n",
    "        df2 = df2.drop(columns=[' Destination Port'])\n",
    "        print(\"Removed ' Destination Port' from df_2.\")\n",
    "\n",
    "    # 1) Coalesce duplicate-normalized columns within each DF\n",
    "    df1 = _coalesce_duplicate_normalized_columns(df1, normalize_name)\n",
    "    df2 = _coalesce_duplicate_normalized_columns(df2, normalize_name)\n",
    "\n",
    "    # 2) Build normalized key sets\n",
    "    df1_norm = {col: normalize_name(col) for col in df1.columns}\n",
    "    df2_norm = {col: normalize_name(col) for col in df2.columns}\n",
    "\n",
    "    # 3) Decide canonical labels per normalized key\n",
    "    #    Preference: use df1's original column name if any; otherwise df2's\n",
    "    norm_to_canon = {}\n",
    "\n",
    "    # First pass: take df1’s original as canonical for its normalized keys\n",
    "    for col, key in df1_norm.items():\n",
    "        # Pick the first-seen df1 original as canonical label for this key\n",
    "        norm_to_canon.setdefault(key, col)\n",
    "\n",
    "    # Second pass: add missing keys from df2, using df2's original\n",
    "    for col, key in df2_norm.items():\n",
    "        norm_to_canon.setdefault(key, col)\n",
    "\n",
    "    # 4) Build per-DF rename maps (original -> canonical)\n",
    "    df1_rename = {col: norm_to_canon[df1_norm[col]] for col in df1.columns}\n",
    "    df2_rename = {col: norm_to_canon[df2_norm[col]] for col in df2.columns}\n",
    "\n",
    "    # 5) Rename\n",
    "    df1_renamed = df1.rename(columns=df1_rename)\n",
    "    df2_renamed = df2.rename(columns=df2_rename)\n",
    "\n",
    "    # 6) After renaming, ensure no duplicates remain (defensive)\n",
    "    if not pd.Index(df1_renamed.columns).is_unique:\n",
    "        # coalesce again just in case renaming produced duplicates\n",
    "        df1_renamed = _coalesce_duplicate_normalized_columns(df1_renamed, normalize_name)\n",
    "        # sanity: re-run uniqueness check\n",
    "        if not pd.Index(df1_renamed.columns).is_unique:\n",
    "            dups = df1_renamed.columns[df1_renamed.columns.duplicated()].tolist()\n",
    "            raise ValueError(f\"df1 still has duplicate columns after coalescing: {dups}\")\n",
    "\n",
    "    if not pd.Index(df2_renamed.columns).is_unique:\n",
    "        df2_renamed = _coalesce_duplicate_normalized_columns(df2_renamed, normalize_name)\n",
    "        if not pd.Index(df2_renamed.columns).is_unique:\n",
    "            dups = df2_renamed.columns[df2_renamed.columns.duplicated()].tolist()\n",
    "            raise ValueError(f\"df2 still has duplicate columns after coalescing: {dups}\")\n",
    "\n",
    "    # 7) Build final unified, sorted column set (canonical labels)\n",
    "    all_canonical = sorted(set(df1_renamed.columns).union(df2_renamed.columns))\n",
    "\n",
    "    # 8) Reindex both to the same columns\n",
    "    df1_aligned = df1_renamed.reindex(columns=all_canonical)\n",
    "    df2_aligned = df2_renamed.reindex(columns=all_canonical)\n",
    "\n",
    "    # Ensure 'Label' column is at the end\n",
    "    for df in (df1_aligned, df2_aligned):\n",
    "        if \"Label\" in df.columns:\n",
    "            lbl = df.pop(\"Label\")\n",
    "            df[\"Label\"] = lbl\n",
    "\n",
    "    return df1_aligned, df2_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9ff3b11-65b0-4363-b48b-fd14d5970fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ' Destination Port' from df_2.\n",
      "\n",
      "--- After Alignment and Sorting ---\n",
      "df_1_aligned columns: ['ACK Flag Count', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Average Packet Size', 'Bwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Bwd Header Length', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Total', 'Bwd Init Win Bytes', 'Bwd PSH Flags', 'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Bwd Packet Length Min', 'Bwd Packet Length Std', 'Bwd Packet/Bulk Avg', 'Bwd Packets/s', 'Bwd Segment Size Avg', 'Bwd URG Flags', 'CWR Flag Count', 'Down/Up Ratio', 'ECE Flag Count', 'FIN Flag Count', 'FWD Init Win Bytes', 'Flow Bytes/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Packets/s', 'Fwd Act Data Pkts', 'Fwd Bulk Rate Avg', 'Fwd Bytes/Bulk Avg', 'Fwd Header Length', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Total', 'Fwd PSH Flags', 'Fwd Packet Length Max', 'Fwd Packet Length Mean', 'Fwd Packet Length Min', 'Fwd Packet Length Std', 'Fwd Packet/Bulk Avg', 'Fwd Packets/s', 'Fwd Seg Size Min', 'Fwd Segment Size Avg', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'PSH Flag Count', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Min', 'Packet Length Std', 'Packet Length Variance', 'RST Flag Count', 'SYN Flag Count', 'Subflow Bwd Bytes', 'Subflow Bwd Packets', 'Subflow Fwd Bytes', 'Subflow Fwd Packets', 'Total Bwd packets', 'Total Fwd Packet', 'Total Length of Bwd Packet', 'Total Length of Fwd Packet', 'URG Flag Count', 'Label']\n",
      "df_2_aligned columns: ['ACK Flag Count', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Average Packet Size', 'Bwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Bwd Header Length', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Total', 'Bwd Init Win Bytes', 'Bwd PSH Flags', 'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Bwd Packet Length Min', 'Bwd Packet Length Std', 'Bwd Packet/Bulk Avg', 'Bwd Packets/s', 'Bwd Segment Size Avg', 'Bwd URG Flags', 'CWR Flag Count', 'Down/Up Ratio', 'ECE Flag Count', 'FIN Flag Count', 'FWD Init Win Bytes', 'Flow Bytes/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Packets/s', 'Fwd Act Data Pkts', 'Fwd Bulk Rate Avg', 'Fwd Bytes/Bulk Avg', 'Fwd Header Length', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Total', 'Fwd PSH Flags', 'Fwd Packet Length Max', 'Fwd Packet Length Mean', 'Fwd Packet Length Min', 'Fwd Packet Length Std', 'Fwd Packet/Bulk Avg', 'Fwd Packets/s', 'Fwd Seg Size Min', 'Fwd Segment Size Avg', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'PSH Flag Count', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Min', 'Packet Length Std', 'Packet Length Variance', 'RST Flag Count', 'SYN Flag Count', 'Subflow Bwd Bytes', 'Subflow Bwd Packets', 'Subflow Fwd Bytes', 'Subflow Fwd Packets', 'Total Bwd packets', 'Total Fwd Packet', 'Total Length of Bwd Packet', 'Total Length of Fwd Packet', 'URG Flag Count', 'Label']\n",
      "Comparison Result: {'are_identical': True, 'in_df1_only': [], 'in_df2_only': [], 'order_mismatch': False}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_1_aligned, df_2_aligned = align_and_sort_dataframes(df_1, df_2)\n",
    "\n",
    "print(\"\\n--- After Alignment and Sorting ---\")\n",
    "print(f\"df_1_aligned columns: {df_1_aligned.columns.tolist()}\")\n",
    "print(f\"df_2_aligned columns: {df_2_aligned.columns.tolist()}\")\n",
    "print(f\"Comparison Result: {compare_df_columns(df_1_aligned, df_2_aligned)}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb325523-d3f7-4820-abbd-0f0940ca566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cat = np.array([0, 15, 23, 24, 26, 27, 45, 54, 59, 65, 66, 75])\n",
    "\n",
    "np.save( \"catfeaturelist.npy\", cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d22f1fb6-fba2-47d6-8448-a55db5d38251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_aligned.to_csv('UNSWNB15_standardised.csv', index=False) \n",
    "df_2_aligned.to_csv('CICIDS2017_standardised.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb3e5d4-a05a-40bb-9355-b7a8f58bb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iat = np.array([9,10,11,12,13,31,32,33,34,40,41,42,43,44])\n",
    "np.save(\"iatfeaturelist.npy\", iat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d67b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatekeeperenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
